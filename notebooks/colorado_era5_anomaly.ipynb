{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c594730-cd0f-4b32-9999-3f5860700da5",
   "metadata": {},
   "source": [
    "# Access ERA5 data from glade and plot temp anomaly for Colorado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3092ae29-feec-45fc-873f-a06016571083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import intake_esm\n",
    "import intake\n",
    "import pandas as pd\n",
    "import cartopy.crs as ccrs  # Correct import for coordinate reference systems\n",
    "import cartopy.feature as cfeature\n",
    "from holoviews import opts\n",
    "import geoviews as gv\n",
    "import holoviews as hv\n",
    "import aiohttp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bb3a80-b011-43fc-822f-68c7d65b10be",
   "metadata": {},
   "source": [
    "### Specify global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dd4beb-490e-4f7b-b4a4-9d8bc5df9d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = 40.014\n",
    "lon =  -105.270 + 360\n",
    "# Bounding box for Colorado\n",
    "colorado_right  =  (-109.060253 + 360)%360\n",
    "colorado_left   = (-102.041524 + 360)%360 \n",
    "colorado_bottom = 37\n",
    "colorado_top    = 41\n",
    "###\n",
    "baseline_year = 1940\n",
    "current_year  = 2023\n",
    "day           = 11\n",
    "month         = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddb79d7-3c23-4fdf-b7b8-59326c1737c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rda_data          = '/gpfs/csfs1/collections/rda/data/'\n",
    "rda_url           = 'https://data.rda.ucar.edu/'\n",
    "era5_catalog      = rda_data + 'pythia_intake_catalogs/'\n",
    "complete_url      = rda_url + 'pythia_intake_catalogs/'  + 'era5_catalog.json'\n",
    "alternate_catalog = rda_data + 'pythia_intake_catalogs/era5_catalog.json'\n",
    "print(complete_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba8b45d-b43d-4489-b3fb-34583428e546",
   "metadata": {},
   "source": [
    "### Create a Dask cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6109afeb-ef72-4a47-bdf0-56504054588f",
   "metadata": {},
   "source": [
    "#### Dask Introduction\n",
    "\n",
    "[Dask](https://www.dask.org/) is a solution that enables the scaling of Python libraries. It mimics popular scientific libraries such as numpy, pandas, and xarray that enables an easier path to parallel processing without having to refactor code. \n",
    "\n",
    "There are 3 components to parallel processing with Dask: the client, the scheduler, and the workers. \n",
    "\n",
    "The Client is best envisioned as the application that sends information to the Dask cluster. In Python applications this is handled when the client is defined with `client = Client(CLUSTER_TYPE)`. A Dask cluster comprises of a single scheduler that manages the execution of tasks on workers. The `CLUSTER_TYPE` can be defined in a number of different ways.\n",
    "\n",
    "- There is LocalCluster, a cluster running on the same hardware as the application and sharing the available resources, directly in Python with `dask.distributed`. \n",
    "\n",
    "- In certain JupyterHubs Dask Gateway may be available and a dedicated dask cluster with its own resources can be created dynamically with `dask.gateway`. \n",
    "\n",
    "- On HPC systems `dask_jobqueue` is used to connect to the HPC Slurm and PBS job schedulers to provision resources.\n",
    "\n",
    "The `dask.distributed` client python module can also be used to connect to existing clusters. A Dask Scheduler and Workers can be deployed in containers, or on Kubernetes, without using a Python function to create a dask cluster. The `dask.distributed` Client is configured to connect to the scheduler either by container name, or by the Kubernetes service name.     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756464b7-5c18-4fbf-ae11-86688c0c4f43",
   "metadata": {},
   "source": [
    "#### Select the Dask cluster type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206e90c1-1764-440f-9846-aa6e75d39777",
   "metadata": {},
   "source": [
    "The default will be LocalCluster as that can run on any system.\n",
    "\n",
    "If running on a HPC computer with a PBS Scheduler, set to True. Otherwise, set to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eba78f-3a1c-4d9a-ad07-501f713069aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_PBS_SCHEDULER = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26672bdd-25d4-4664-bd2f-09eac8e578ba",
   "metadata": {},
   "source": [
    "If running on Jupyter server with Dask Gateway configured, set to True. Otherwise, set to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4804f8c9-a5f2-4ed7-a5a4-fdb9c344e5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_DASK_GATEWAY = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296bfaf7-a1a4-48f7-b3f2-e2b12a738660",
   "metadata": {},
   "source": [
    "**Python function for a PBS Cluster**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0915ebf-a4b9-4089-b5da-b81fc5f96488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PBS cluster object\n",
    "def get_pbs_cluster():\n",
    "    \"\"\" Create cluster through dask_jobqueue.   \n",
    "    \"\"\"\n",
    "    from dask_jobqueue import PBSCluster\n",
    "    cluster = PBSCluster(\n",
    "        job_name = 'dask-pythia-24',\n",
    "        cores = 1,\n",
    "        memory = '4GiB',\n",
    "        processes = 1,\n",
    "        local_directory = rda_scratch + '/dask/spill',\n",
    "        resource_spec = 'select=1:ncpus=1:mem=4GB',\n",
    "        queue = 'casper',\n",
    "        walltime = '1:00:00',\n",
    "        #interface = 'ib0'\n",
    "        interface = 'ext'\n",
    "    )\n",
    "    return cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad45401-97c9-4934-9b97-97ac1c9edd3c",
   "metadata": {},
   "source": [
    "**Python function for a Gateway Cluster**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdeb643-324e-4b76-a902-884d1c2b7d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gateway_cluster():\n",
    "    \"\"\" Create cluster through dask_gateway\n",
    "    \"\"\"\n",
    "    from dask_gateway import Gateway\n",
    "\n",
    "    gateway = Gateway()\n",
    "    cluster = gateway.new_cluster()\n",
    "    cluster.adapt(minimum=2, maximum=4)\n",
    "    return cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9274168c-11e4-4db2-b5b3-6c818e25b8cf",
   "metadata": {},
   "source": [
    "**Python function for a Local Cluster**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cf2e6a-9617-4873-9c58-649f524cd74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_cluster():\n",
    "    \"\"\" Create cluster using the Jupyter server's resources\n",
    "    \"\"\"\n",
    "    from distributed import LocalCluster, performance_report\n",
    "    cluster = LocalCluster()    \n",
    "\n",
    "    cluster.scale(4)\n",
    "    return cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d28e5d-16f6-492a-b4ab-cc54015c7ea1",
   "metadata": {},
   "source": [
    "**Python logic to select the Dask Cluster type**\n",
    "\n",
    "This uses True/False boolean logic based on the variables set in the previous cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ceadbf-2d3c-42a4-aaf0-a13ecc3c86c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain dask cluster in one of three ways\n",
    "\n",
    "if USE_PBS_SCHEDULER:\n",
    "    cluster = get_pbs_cluster()\n",
    "elif USE_DASK_GATEWAY:\n",
    "    cluster = get_gateway_cluster()\n",
    "else:\n",
    "    cluster = get_local_cluster()\n",
    "\n",
    "# Connect to cluster\n",
    "from distributed import Client\n",
    "client = Client(cluster)\n",
    "\n",
    "# Display cluster dashboard URL\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced69791-8589-4ec7-9961-edd56e4bb014",
   "metadata": {},
   "source": [
    "### Open ERA5 catalog "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d432d9-1c63-4907-b6c5-0eb5d2499714",
   "metadata": {},
   "outputs": [],
   "source": [
    "era5_cat = intake.open_esm_datastore(complete_url)\n",
    "#era5_cat = intake.open_esm_datastore(alternate_catalog)\n",
    "era5_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90cbf01-6547-4a39-b9b6-da8466939ecb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "era5_df = era5_cat.df\n",
    "era5_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595dd0c1-b99c-4f9c-a6b6-9938add0c68f",
   "metadata": {},
   "source": [
    "- Explore the list of variables to find the name of the 2m air temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a973e1-2eea-4a3e-9329-36630d47c582",
   "metadata": {},
   "outputs": [],
   "source": [
    "era5_df['variable'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112c04a4-552a-4667-adde-8d37679b1b7e",
   "metadata": {},
   "source": [
    "- We find that the variable of interest is called 'VAR_2T'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d32a0d1-9097-4c25-9520-bb01440eabbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_cat = era5_cat.search(variable='VAR_2T',frequency = 'hourly')\n",
    "temp_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eec86f7-5e13-43f4-9967-e8c47bc9d334",
   "metadata": {},
   "source": [
    "- Convert catalog to dictonary\n",
    "- Inspect keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f49404b-1594-4713-8aa5-b0f5a6e0787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the xarray_open_kwargs with a compatible engine, for example, 'scipy'\n",
    "xarray_open_kwargs = {\n",
    "    'engine': 'h5netcdf',\n",
    "    'chunks': {},  # Specify any chunking if needed\n",
    "    'backend_kwargs': {}  # Any additional backend arguments if required\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec32e95-61ba-4e68-9bd0-3dbcf5c3108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xr.open_dataset ('https://data.rda.ucar.edu/ds633.0/e5.oper.an.sfc/195206/e5.oper.an.sfc.128_167_2t.ll025sc.1952060100_1952063023.nc#mode=bytes',engine='netcdf4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04941db-9d52-4508-8f12-09a3ef3f59ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ensure that the catalog entries are correctly handled\n",
    "# for key in temp_cat.df['path']:\n",
    "#     print(f\"Processing {key}\")h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8ee2b6-5732-4062-82f0-dea7ebf27cdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dsets = temp_cat.to_dataset_dict(xarray_open_kwargs=xarray_open_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd05df0a-1119-4b5a-8e22-f191d8697d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_cat['an.sfc'].df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a830e91-fbec-4438-97e3-de670725f5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6354a0ce-36fe-4b9d-a44a-005b0119d6fe",
   "metadata": {},
   "source": [
    "- Extract dataset using dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9958845-ac92-4fe7-bd6f-62d27ca00981",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_2m = dsets['an.sfc'].VAR_2T\n",
    "temp_2m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f909bd-bbd4-4bfb-931d-2e3d136ce255",
   "metadata": {},
   "source": [
    "- Select data corresponding to the dayofyear and colorado for the years baseline_year and current_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8585c8f2-c89c-4a82-b184-05284920bd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas Timestamp\n",
    "current_date  = pd.Timestamp(year=current_year, month=month, day=day)\n",
    "baseline_date =  pd.Timestamp(year=baseline_year, month=month, day=day)\n",
    "current_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ee90d5-666d-41a4-94f9-1b0a77162142",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2m_colorado_current = temp_2m.sel(latitude=slice(colorado_top,colorado_bottom),\\\n",
    "                                         longitude=slice(colorado_right,colorado_left)).sel(time=slice(current_date,current_date+  pd.Timedelta(days=1)))\n",
    "t2m_colorado_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de91a835-1948-425f-a2ca-d41afe4bdd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2m_colorado_baseline = temp_2m.sel(latitude=slice(colorado_top,colorado_bottom),\\\n",
    "                                         longitude=slice(colorado_right,colorado_left)).sel(time=slice(current_date,current_date+  pd.Timedelta(days=1)))\n",
    "t2m_colorado_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b456b2-fae3-4f39-a5bb-3ee348c9a987",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_t2m_colorado_anomaly = t2m_colorado_current.max('time') - t2m_colorado_baseline.max('time')\n",
    "max_t2m_colorado_anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ab5f62-057b-41c6-b361-12db33ca2f7f",
   "metadata": {},
   "source": [
    "## Let us now plot this data with a map of Colorado in the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9640b391-d171-4e92-95d8-873f9cffd1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the latitude, longitude, and data\n",
    "latitude = max_t2m_colorado_anomaly['latitude'].values\n",
    "longitude = max_t2m_colorado_anomaly['longitude'].values\n",
    "max_t2m_colorado_anomaly = max_t2m_colorado_anomaly.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3430d5-f436-45a3-9554-e6d22e14ce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot\n",
    "proj = ccrs.PlateCarree(central_longitude=180)\n",
    "tiles = gv.tile_sources.ESRI()\n",
    "\n",
    "# Define the state borders feature\n",
    "states = cfeature.NaturalEarthFeature(\n",
    "    category='cultural',\n",
    "    name='admin_1_states_provinces_lines',\n",
    "    scale='110m',\n",
    "    facecolor='none'\n",
    ")\n",
    "\n",
    "# Create a GeoViews plot\n",
    "plot = gv.Image((longitude, latitude, max_t2m_colorado_anomaly), crs=proj, vdims='value').opts(\n",
    "    cmap='viridis',\n",
    "    colorbar=True,\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "# Add state borders and other features\n",
    "state_borders = gv.feature.Feature(states, group='State Borders').opts(line_color='black')\n",
    "# borders = gv.feature.borders.opts(line_dash='dotted', zorder=2)\n",
    "# state_lines = gv.feature.states.opts(line_color='black', zorder=3)\n",
    "# borders = gv.feature.borders.opts(line_dash='dotted')\n",
    "# state_lines = gv.feature.states.opts(line_color='black')\n",
    "\n",
    "# Combine everything into a single plot\n",
    "final_plot = tiles * plot * state_borders * borders * state_lines\n",
    "\n",
    "# Display the plot\n",
    "hv.extension('bokeh')\n",
    "final_plot.opts(\n",
    "    opts.Overlay(projection=ccrs.PlateCarree(central_longitude=180), global_extent=False),\n",
    "    opts.Image(tools=['hover']),\n",
    "    opts.Feature(line_width=1.5)\n",
    ").opts(\n",
    "    opts.GridSpace(show_title=True, shared_xaxis=True, shared_yaxis=True, height=400, width=600)\n",
    ")\n",
    "\n",
    "# To add grid lines with labels, use the options on the plot directly\n",
    "final_plot.opts(\n",
    "    opts.Image(xaxis='bottom', yaxis='left', show_grid=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b49979-a521-4be0-9fd8-6d41891c8261",
   "metadata": {},
   "source": [
    "## Close the Dask Cluster\n",
    "\n",
    "It's best practice to close the Dask cluster when it's no longer needed to free up the compute resources used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e51dddc-0c52-4299-8f19-57952838de91",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848d1fa1-85b5-4823-b9ee-bbee06c16e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2024a",
   "language": "python",
   "name": "npl-2024a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
